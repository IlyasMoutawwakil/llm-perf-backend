defaults:
  - backend: pytorch
  - _base_ # inheriting from base config
  - _self_ # for hydra 1.1 compatibility

experiment_name: pytorch+cuda+float16+flash-attention-v2
device: cuda

backend:
  no_weights: true
  torch_dtype: float16
  use_flash_attention_v2: true

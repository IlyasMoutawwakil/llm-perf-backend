name: LLM Perf Benchmarks on NVIDIA GPUs

on:
  workflow_dispatch:
  schedule:
    # every Monday at 00:00 UTC
    - cron: "0 0 * * 1"

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: false

jobs:
  build_image:
    strategy:
      matrix:
        runner: [hf-dgx-01]

    runs-on: ${{ matrix.runner }}
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Build image
        run: docker build
          --file docker/cuda.dockerfile
          --build-arg USER_ID=$(id -u)
          --build-arg GROUP_ID=$(id -g)
          --build-arg CUDA_VERSION=11.8.0
          --build-arg TORCH_CUDA=cu118
          --tag llm-perf-cuda:11.8.0
          .

  run_benchmarks:
    needs: build_image
    strategy:
      matrix:
        runner: [hf-dgx-01]

    runs-on: ${{ matrix.runner }}
    steps:
      - name: Run tests
        run: docker run
          --rm
          --net host
          --pid host
          --gpus '"device=4"'
          --entrypoint /bin/bash
          --env HF_TOKEN=$HF_TOKEN
          --volume $HOME/.cache/huggingface:/home/user/.cache/huggingface
          --volume $(pwd):/workspace/llm-perf
          --workdir /workspace/llm-perf
          llm-perf-cuda:11.8.0
          -c "pip install -r requirements/cuda118.txt --no-build-isolation ;

          python scripts/pull_dataset.py &&

          python scripts/benchmark.py --config pytorch+cuda+float32 &&
          python scripts/benchmark.py --config pytorch+cuda+float16 &&
          python scripts/benchmark.py --config pytorch+cuda+bfloat16 &&
          python scripts/benchmark.py --config pytorch+cuda+float16+bettertransformer &&
          python scripts/benchmark.py --config pytorch+cuda+float16+flash-attention-v2 &&

          python scripts/benchmark.py --config pytorch+cuda+float16+bnb-4bit &&
          python scripts/benchmark.py --config pytorch+cuda+float16+bnb-8bit &&
          python scripts/benchmark.py --config pytorch+cuda+float16+bnb-4bit+bettertransformer &&
          python scripts/benchmark.py --config pytorch+cuda+float16+bnb-8bit+bettertransformer &&
          python scripts/benchmark.py --config pytorch+cuda+float16+bnb-4bit+flash-attention-v2 &&
          python scripts/benchmark.py --config pytorch+cuda+float16+bnb-8bit+flash-attention-v2 &&

          python scripts/benchmark.py --config pytorch+cuda+float16+gptq-4bit+cuda-fp16 &&
          python scripts/benchmark.py --config pytorch+cuda+float16+gptq-4bit+exllama-v1 &&
          python scripts/benchmark.py --config pytorch+cuda+float16+gptq-4bit+exllama-v2 &&

          python scripts/push_dataset.py"
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
